{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Y-a4g98w93GHswXLRLoiogvMYNPgzPE9","timestamp":1731170796528}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"code","source":[],"metadata":{"id":"u-PbRvvV3wt8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"I79-VZ-r3OBU","executionInfo":{"status":"ok","timestamp":1731172029118,"user_tz":-60,"elapsed":1023,"user":{"displayName":"Gianmario Iamoni","userId":"07995532745716785055"}},"outputId":"b9504a78-1a7b-47a7-9842-7fbb80dd6bc0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.17.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":[],"metadata":{"id":"D7_A0GG841--"}},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","source":["# Preprocessing the Training set\n","#\n","# We will apply transformations to traning set images to avoid overfitting\n","# This is called Image Augmentation\n","#\n","# We use the ImageDataGeneration class\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255, # features scaling\n","        shear_range=0.2, # transformation 1\n","        zoom_range=0.2, # transformation 2\n","        horizontal_flip=True) # transformation 3\n","\n","# connect the train_datagen to the training_set\n","training_set = train_datagen.flow_from_directory(\n","        'dataset/training_set',\n","        target_size=(64, 64), # final size of the images in the CNN\n","        batch_size=32, # size of the batches (number of images in the batch)\n","        class_mode='binary')\n"],"metadata":{"id":"qwzSYnNJ5UHO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","source":["# Preprocessing the Test set\n","#\n","# We maintain the test set intact, without transformation\n","# but we need to apply features scaling\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","test_set = test_datagen.flow_from_directory(\n","        'dataset/test_set',\n","        target_size=(64, 64),\n","        batch_size=32,\n","        class_mode='binary')"],"metadata":{"id":"ijWwR29C9twX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"markdown","metadata":{"id":"fgFHHVUD484y"},"source":["### Initialising the CNN"]},{"cell_type":"code","source":["# Initialising the CNN\n","cnn = tf.keras.models.Sequential()"],"metadata":{"id":"PPHxSdz45KbA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","source":["# Step 1 - Convolution\n","#\n","# We use the Conv2D class from the layers module belonging to the keras library of TensorFlow\n","# filters: number of features detectors\n","# kernel_size: size of feature detector matrix\n","# activation: activation function\n","# input_shape: shape of the input image (64x64x3)\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"],"metadata":{"id":"z-exwJG65MGF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","source":["# Step 2 - Pooling\n","#\n","# Applying max pooling\n","# pool_size: size of pool square matrix (2x2)\n","# strides: number of pixels the pool matrix is shifted to the right\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"metadata":{"id":"bXBq7G2G6c5_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","source":["# Adding a second convolutional layer\n","#\n","# input_shape parmeter is need only in the 1st layer\n","cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n"],"metadata":{"id":"TWuZ5fBG0-N-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","source":["# Step 3 - Flattening\n","#\n","# We use the Flatten class from the layers module belonging to the keras library of TensorFlow\n","cnn.add(tf.keras.layers.Flatten())"],"metadata":{"id":"FaN2vTup7ogn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","source":["# Step 4 - Full Connection\n","#\n","# We use the Dense class from the layers module belonging to the keras library of TensorFlow\n","# units: number of hidden neurons\n","# activation: activation function\n","cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"],"metadata":{"id":"otcVzJTS76so"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","source":["# Step 5 - Output Layer\n","#\n","# We use the Dense class from the layers module belonging to the keras library of TensorFlow\n","# units: number of output neurons (binary classification in this case)\n","# activation: activation function ('sigmoid' for the output layer)\n","cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"waziciob8XPq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","source":["# Part 3 - Training the CNN\n","#\n","# Compiling the CNN\n","# optimizer: 'adam'\n","# loss function: 'binary_crossentropy\n","# metric: 'accuracy'\n","cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"],"metadata":{"id":"VOWFBNn89DH2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","source":["# Training the CNN on the Training set and evaluating it on the Test set\n","#\n","# We use 25 epochs (by temptatives)\n","cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"],"metadata":{"id":"7Z8LxllJ9jJl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","source":["# Part 4 - Making a single prediction\n","#\n","# We deploy the CNN for each of 2 prediction images\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","# load a single image to which we want to deploy the CNN\n","# The image has to have the same size of the images we used for the training (64x64 in this case)\n","test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n","# convert the image in an numpy array, expected by the CNN as input\n","test_image = image.img_to_array(test_image)\n","# CNN was trained on batches of images. The single image has to be in a batch\n","# we add an extra dimension corresponding to the bacth;\n","# axis: where we want to add the extra dimension (first dimension = 0)\n","test_image = np.expand_dims(test_image, axis = 0)\n","# deploy the CNN\n","result = cnn.predict(test_image)\n","# print the right class indeces\n","training_set.class_indices\n","# encoding the result (result is in a batch, so is a 2d array)\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'\n","\n","print(prediction)\n"],"metadata":{"id":"879RPUKW-VkW"},"execution_count":null,"outputs":[]}]}